{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import pandas\n",
    "import numpy\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, RandomContrast, RandomBrightness, Flip, OneOf, Compose, RandomGamma, ElasticTransform, ChannelShuffle,RGBShift, Rotate\n",
    ")\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "from PIL.Image import Path\n",
    "import colorsys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(aug, image):\n",
    "    return aug(image=image)['image']\n",
    "\n",
    "def strong_aug(p=1):\n",
    "    return Compose([\n",
    "        RandomRotate90(),\n",
    "        Flip(),\n",
    "        Transpose(),\n",
    "        OneOf([\n",
    "            IAAAdditiveGaussianNoise(),\n",
    "            GaussNoise(),\n",
    "        ], p=0.2),\n",
    "        OneOf([\n",
    "            MotionBlur(p=.2),\n",
    "            MedianBlur(blur_limit=3, p=.1),\n",
    "            Blur(blur_limit=3, p=.1),\n",
    "        ], p=0.2),\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=.2),\n",
    "        OneOf([\n",
    "            OpticalDistortion(p=0.3),\n",
    "            GridDistortion(p=.1),\n",
    "            IAAPiecewiseAffine(p=0.3),\n",
    "        ], p=0.2),\n",
    "        OneOf([\n",
    "            CLAHE(clip_limit=2),\n",
    "            IAASharpen(),\n",
    "            IAAEmboss(),\n",
    "            RandomContrast(),\n",
    "            RandomBrightness(),\n",
    "        ], p=0.3),\n",
    "        #HueSaturationValue(p=0.3),\n",
    "    ], p=p)\n",
    "\n",
    "aug = strong_aug(p=3)  \n",
    "\n",
    "for i in range(1, len(os.listdir('c:\\\\users\\\\admin\\\\dataset\\\\1'))):\n",
    "    for b in range(5):\n",
    "        image = Image.open(Path('C:/Users/admin/dataset/1/image (' + str(i) + ').jpg'))\n",
    "        new_image = Image.fromarray(augment(aug,np.array(image)))\n",
    "        new_image.save('C:/Users/admin/dataset/1_aug/new_image (' + str(i) + '_' + str(b)+').jpg')  \n",
    "        \n",
    "for i in range(1, len(os.listdir('c:\\\\users\\\\admin\\\\dataset\\\\0'))):\n",
    "    for b in range(5):\n",
    "        image = Image.open(Path('C:/Users/admin/dataset/0/image (' + str(i) + ').jpg'))\n",
    "        new_image = Image.fromarray(augment(aug,np.array(image)))\n",
    "        new_image.save('C:/Users/admin/dataset/0_aug/new_image (' + str(i) + '_' + str(b)+').jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = os.listdir('c:\\\\users\\\\admin\\\\dataset\\\\0\\\\')\n",
    "counter = 1\n",
    "for i in names_list:\n",
    "#     im = Image.open(Path('C:/Users/admin/dataset/0/image (' + str(i) + ').jpg'))\n",
    "#     ld = im.load()\n",
    "\n",
    "#     width, height = im.size\n",
    "#     for y in range(height):\n",
    "#         for x in range(width):\n",
    "#             r,g,b = ld[x,y]\n",
    "#             h,s,v = colorsys.rgb_to_hsv(r/255., g/255., b/255.)\n",
    "\n",
    "#             if s>0.5:                   \n",
    "#                 ld[x,y] = (0,0,0)\n",
    "#             else:\n",
    "#                 ld[x,y] = (255,255,255)\n",
    "#     im.save('C:/Users/admin/dataset/0_bin/new_image (' + str(i) + '_' + str(b)+').jpg')\n",
    "    img = cv.imread('C:/Users/admin/dataset/0/' + i,0)\n",
    "#     img = cv.medianBlur(img,5)\n",
    "#     th3 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "#             cv.THRESH_BINARY,11,2)\n",
    "    #blur = cv.GaussianBlur(img,(5,5),0)\n",
    "    ret2,th2 = cv.threshold(img,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "    cv.imwrite('C:/Users/admin/dataset/0_bin/new_image (' + str(counter) + ').jpg', th2)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = os.listdir('c:\\\\users\\\\admin\\\\dataset\\\\1\\\\')\n",
    "counter = 1\n",
    "for i in names_list:\n",
    "#     im = Image.open(Path('C:/Users/admin/dataset/0/image (' + str(i) + ').jpg'))\n",
    "#     ld = im.load()\n",
    "\n",
    "#     width, height = im.size\n",
    "#     for y in range(height):\n",
    "#         for x in range(width):\n",
    "#             r,g,b = ld[x,y]\n",
    "#             h,s,v = colorsys.rgb_to_hsv(r/255., g/255., b/255.)\n",
    "\n",
    "#             if s>0.5:                   \n",
    "#                 ld[x,y] = (0,0,0)\n",
    "#             else:\n",
    "#                 ld[x,y] = (255,255,255)\n",
    "#     im.save('C:/Users/admin/dataset/0_bin/new_image (' + str(i) + '_' + str(b)+').jpg')\n",
    "    img = cv.imread('C:/Users/admin/dataset/1/' + i,0)\n",
    "#     img = cv.medianBlur(img,5)\n",
    "#     th3 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "#             cv.THRESH_BINARY,11,2)\n",
    "    #blur = cv.GaussianBlur(img,(5,5),0)\n",
    "    ret2,th2 = cv.threshold(img,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "    cv.imwrite('C:/Users/admin/dataset/1_bin/new_image (' + str(counter) + ').jpg', th2)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.RandomResizedCrop(390),\n",
    "     torchvision.transforms.RandomRotation(degrees=15),\n",
    "     torchvision.transforms.RandomHorizontalFlip(244),\n",
    "     torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "ngpu = 1\n",
    "#device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "def load_dataset():\n",
    "    data_path = 'dataset/'\n",
    "    train_dataset = torchvision.datasets.ImageFolder(\n",
    "        root=data_path,\n",
    "        transform=transform\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=25,\n",
    "        num_workers=0,\n",
    "        shuffle=True\n",
    "    )\n",
    "    return train_loader\n",
    "\n",
    "dataloader = load_dataset()\n",
    "classes = os.listdir('dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     \n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dataiter = iter(dataloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet101(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_inputs = resnet50.fc.in_features\n",
    " \n",
    "resnet50.fc = nn.Sequential(\n",
    "    nn.Linear(fc_inputs, 390),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(390, 2),\n",
    "    nn.LogSoftmax(dim=1) # For using NLLLoss()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet50.load_state_dict(torch.load('c:\\\\users\\\\admin\\\\desktop\\\\resnet.pt'))\n",
    "#resnet50.eval()\n",
    "resnet50 = resnet50.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(resnet50.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for epoch in range(20):\n",
    "    epoch_start = time.time()\n",
    "    print(\"Epoch: {}/{}\".format(epoch+1, 20))\n",
    "     \n",
    "    # Set to training mode\n",
    "    resnet50.train()\n",
    "     \n",
    "    # Loss and Accuracy within the epoch\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    " \n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    " \n",
    "        inputs = inputs.to('cuda:0')\n",
    "        labels = labels.to('cuda:0')\n",
    "         \n",
    "        # Clean existing gradients\n",
    "        #optimizer.zero_grad()\n",
    "         \n",
    "        # Forward pass - compute outputs on input data using the model\n",
    "        outputs = resnet50(inputs)\n",
    "         \n",
    "        # Compute loss\n",
    "        loss = loss_criterion(outputs, labels)\n",
    "         \n",
    "        # Backpropagate the gradients\n",
    "        loss.backward()\n",
    "         \n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "         \n",
    "        # Compute the total loss for the batch and add it to train_loss\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "         \n",
    "        # Compute the accuracy\n",
    "        ret, predictions = torch.max(outputs.data, 1)\n",
    "        correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "         \n",
    "        # Convert correct_counts to float and then compute the mean\n",
    "        acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "         \n",
    "        # Compute total accuracy in the whole batch and add to train_acc\n",
    "        train_acc += acc.item() * inputs.size(0)\n",
    "         \n",
    "        print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet50.state_dict(), 'c:\\\\users\\\\admin\\\\Desktop\\\\resnet_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "image = Image.open(Path('C:/Users/admin/desktop/example_1.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('C:/Users/admin/desktop/example_1.jpg',0)\n",
    "ret2,th2 = cv.threshold(img,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "cv.imwrite('C:/Users/admin/desktop/example_new_1.jpg', th2)\n",
    "image = Image.open(Path('C:/Users/admin/desktop/example_new_1.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.RandomResizedCrop(390),\n",
    "     #torchvision.transforms.RandomRotation(degrees=15),\n",
    "     #torchvision.transforms.RandomHorizontalFlip(244),\n",
    "     torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "input = transform(image)\n",
    "input = input.view(1, 3, 390, 390)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)\n",
    "fc_inputs = resnet50.fc.in_features\n",
    " \n",
    "resnet50.fc = nn.Sequential(\n",
    "    nn.Linear(fc_inputs, 244),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(244, 2),\n",
    "    nn.LogSoftmax(dim=1) # For using NLLLoss()\n",
    ")\n",
    "resnet50.load_state_dict(torch.load('c:\\\\users\\\\admin\\\\desktop\\\\resnet.pt'))\n",
    "resnet50.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = resnet50(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = int(torch.max(output.data, 1)[1].numpy())\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "image = Image.open(Path('C:/Users/admin/desktop/example_1.jpg'))\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.RandomResizedCrop(390),\n",
    "     torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "input = transform(image)\n",
    "input = input.view(1, 3, 390, 390)\n",
    "\n",
    "resnet50 = models.resnet50(pretrained=True)  #модель скачается автоматически если не скачана\n",
    "fc_inputs = resnet50.fc.in_features\n",
    " \n",
    "resnet50.fc = nn.Sequential(\n",
    "    nn.Linear(fc_inputs, 244),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(244, 2),\n",
    "    nn.LogSoftmax(dim=1) # For using NLLLoss()\n",
    ")\n",
    "resnet50.load_state_dict(torch.load('c:\\\\users\\\\admin\\\\desktop\\\\resnet.pt'))\n",
    "resnet50.eval()\n",
    "\n",
    "output = resnet50(input)\n",
    "prediction = int(torch.max(output.data, 1)[1].numpy())  # результат"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
